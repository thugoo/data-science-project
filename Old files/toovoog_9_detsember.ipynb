{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9d9af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Mudelid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Mutual info\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158c082",
   "metadata": {},
   "source": [
    "## Andmete töötlemine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9896ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file, drop_values=None):\n",
    "    \n",
    "    # Data\n",
    "    data = pd.read_csv(file)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    surnud= data[data[\"DEFINITION_ID\"] == \"death\"]\n",
    "    subject_ids = surnud[\"SUBJECT_ID\"]\n",
    "    \n",
    "    # Filtreerib surnute id põhjal\n",
    "    surnud = data[data[\"SUBJECT_ID\"].isin(subject_ids)]\n",
    "    \n",
    "    # Muudame aja väärtuse 1-ks, ehk esialgsetes andmetes \"DEFINITION_ID\" = TIME, nüüd selle asemel lihtsalt 1.\n",
    "    surnud[\"TIME\"] = 1\n",
    "    elus = data[data[\"DEFINITION_ID\"] != \"death\"]\n",
    "    elus[\"TIME\"] = 1\n",
    "\n",
    "    # Sama toimub ka siin, aga elus patsientidega\n",
    "    elus_filtered = elus[~elus[\"SUBJECT_ID\"].isin(surnud[\"SUBJECT_ID\"])]\n",
    "\n",
    "    # Filtreeritud andmete kombineerimine üheks tabeliks\n",
    "    combined_data = pd.concat([surnud, elus_filtered])\n",
    "    combined_data.sort_values(by='SUBJECT_ID', inplace=True)\n",
    "    combined_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Tagastatav tabel - read on patsiendid, veerud on protseduurid\n",
    "    # 1 = protseduur tehti, 0 = patsient pole protseduuri saanud\n",
    "    # Samuti ka veerg \"death\": 1 = surnud, 0 = \"elus\"\n",
    "    \n",
    "    pivot_combined_data = combined_data.pivot_table(index='SUBJECT_ID', columns='DEFINITION_ID', values='TIME', aggfunc='sum', fill_value=0)\n",
    "    if drop_values:\n",
    "        for value in drop_values:\n",
    "            if value:\n",
    "                cols_to_drop = pivot_combined_data.filter(like=value).columns\n",
    "                pivot_combined_data = pivot_combined_data.drop(columns=cols_to_drop)\n",
    "    return pivot_combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0f6d9",
   "metadata": {},
   "source": [
    "## Tunnuste töötlemine (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7a86fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_important_features(X, save_loadings=False):\n",
    "    n_components=20\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # DataFrame with the principal components\n",
    "    pc_columns = [f'PC_{i+1}' for i in range(n_components)]\n",
    "    \n",
    "    # Variance ratios\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_ \n",
    "    \n",
    "    all_pca_loadings = [loadings for loadings in pca.components_]\n",
    "    \n",
    "    if save_loadings:\n",
    "        loadings_dfs = []\n",
    "        for index, loadings in enumerate(all_pca_loadings):\n",
    "            loadings_df = pd.DataFrame({'Feature': X.columns, f'Loading_PC{index+1}': loadings})\n",
    "            loadings_df[f'Absolute_Loading_PC{index+1}'] = loadings_df[f'Loading_PC{index+1}'].abs()\n",
    "            loadings_df = loadings_df.sort_values(by=f'Absolute_Loading_PC{index+1}', ascending=False)\n",
    "            loadings_dfs.append(loadings_df)\n",
    "        \n",
    "        combined_loadings_df = pd.concat(loadings_dfs, axis=1)\n",
    "        combined_loadings_df.to_csv('combined_loadings.csv', index=False, encoding=\"utf-8\")\n",
    "    \n",
    "    loadings_pc = pca.components_[0]\n",
    "    \n",
    "    # PC1 loadings\n",
    "    loading_df = pd.DataFrame({'Feature': X.columns, 'Loading_PC1': loadings_pc})\n",
    "    # Sorteeritud\n",
    "    loading_df['Absolute_Loading_PC1'] = loading_df['Loading_PC1'].abs()\n",
    "    loading_df = loading_df.sort_values(by='Absolute_Loading_PC1', ascending=False)\n",
    "    \n",
    "    return pd.DataFrame(X_pca, columns=pc_columns), explained_variance_ratio, pca, loading_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb364e9d",
   "metadata": {},
   "source": [
    "## Erinevate mudelite treenimine, valimaks parima mudeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f6518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model_type):\n",
    "    svm_params = {'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'C': 100}\n",
    "    knn_params = {'weights': 'distance', 'p': 2, 'n_neighbors': 16, 'algorithm': 'auto'}\n",
    "    rf_params = {'bootstrap': False, 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "    gradient_params = {'learning_rate': 0.2, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
    "    if model_type == 'RandomForest':\n",
    "        model = RandomForestClassifier(random_state=42,**rf_params)\n",
    "    elif model_type == 'SVM':\n",
    "        model = SVC(probability=True, random_state=42,**svm_params)\n",
    "    elif model_type == 'KNeighbors':\n",
    "        model = KNeighborsClassifier(**knn_params)\n",
    "    elif model_type == \"Gradient\":\n",
    "        model = GradientBoostingClassifier(random_state=42,**gradient_params)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f'Invalid model type: {model_type}')\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde9994",
   "metadata": {},
   "source": [
    "## Mudeli hindamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d659cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    # Mudeli hindamine \n",
    "    y_probabilities = model.predict_proba(X)[:, 1]    \n",
    "    auc_roc = roc_auc_score(y, y_probabilities)\n",
    "    \n",
    "    return auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c35ac7",
   "metadata": {},
   "source": [
    "## Töövoo jooksutamine\n",
    "**PS! Vaata #STEP 2 juures kommentaar \"save_loadings\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dcc91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39770/1291404932.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC-ROC Scores:\n",
      "RandomForest without []: 0.8177918265974261\n",
      "SVM without []: 0.8776247459923233\n",
      "KNeighbors without []: 0.8521110860239333\n",
      "Gradient without []: 0.874689546172951\n",
      "\n",
      "RandomForest without ['condition_']: 0.8453375479792278\n",
      "SVM without ['condition_']: 0.9121697900203206\n",
      "KNeighbors without ['condition_']: 0.8813501919169112\n",
      "Gradient without ['condition_']: 0.9067509595845563\n",
      "\n",
      "RandomForest without ['drug_']: 0.8600135470760895\n",
      "SVM without ['drug_']: 0.8679160081282457\n",
      "KNeighbors without ['drug_']: 0.8517724091216978\n",
      "Gradient without ['drug_']: 0.8902686836757733\n",
      "\n",
      "RandomForest without ['observation_']: 0.8451117633777375\n",
      "SVM without ['observation_']: 0.862045608489501\n",
      "KNeighbors without ['observation_']: 0.8335967487017386\n",
      "Gradient without ['observation_']: 0.841724994355385\n",
      "\n",
      "RandomForest without ['procedure_']: 0.8311131180853466\n",
      "SVM without ['procedure_']: 0.9017836983517724\n",
      "KNeighbors without ['procedure_']: 0.8462406863851886\n",
      "Gradient without ['procedure_']: 0.8471438247911492\n",
      "\n",
      "RandomForest without ['measurement']: 0.7836983517724092\n",
      "SVM without ['measurement']: 0.7577331226010386\n",
      "KNeighbors without ['measurement']: 0.7850530593813502\n",
      "Gradient without ['measurement']: 0.8186949650033867\n",
      "\n",
      "RandomForest without ['drug_', 'condition_', 'procedure_']: 0.9225558816888688\n",
      "SVM without ['drug_', 'condition_', 'procedure_']: 0.9182659742605555\n",
      "KNeighbors without ['drug_', 'condition_', 'procedure_']: 0.9094603748024385\n",
      "Gradient without ['drug_', 'condition_', 'procedure_']: 0.9365545269812598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main(file):\n",
    "    \n",
    "    # PCde loomisel väljajäetavate interventionite kombinatsioonid\n",
    "    drop_value_combinations = [\n",
    "        \n",
    "        # PCde loomine kõikide interventionitega\n",
    "        [], \n",
    "        \n",
    "        # Individuaalsete interventionite väljajätmine, et näha nende mõju AUC-ROC skoorile\n",
    "        [\"condition_\"], \n",
    "        [\"drug_\"], \n",
    "        [\"observation_\"], \n",
    "        [\"procedure_\"], \n",
    "        [\"measurement\"],\n",
    "        \n",
    "        # Kombinatsioon, millega saavutasime parima AUC-ROC skoori\n",
    "        [\"drug_\", \"condition_\", \"procedure_\"]\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    for value_combination in drop_value_combinations:\n",
    "        data = load_data(file, drop_values=value_combination)\n",
    "        X = data.drop(columns=['death'])\n",
    "        y = data['death']\n",
    "\n",
    "        # Salvestame ainult parima kombinatsiooniga PCde loadingud\n",
    "        save_loadings = True if value_combination == [\"drug_\", \"condition_\", \"procedure_\"] else False\n",
    "        \n",
    "        # \"save_loadings=True\" - tekib .csv fail, kust saab hiljem tunnuste osakaalu PC-de moodustamisel vaadata\n",
    "        important_features, explained_variance_ratio, pca, loading_df = identify_important_features(X, save_loadings=save_loadings)\n",
    "        model_types = ['RandomForest','SVM', 'KNeighbors','Gradient']\n",
    "\n",
    "        # Mudelite treenimine (x = important_features ehk mudelid treenitakse genereeritud PCde põhjal)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(important_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        for model_type in model_types:\n",
    "            model = train_model(X_train, y_train, model_type=model_type)\n",
    "            auc_roc = evaluate_model(model, X_test, y_test)\n",
    "            results[f\"{model_type} without {value_combination}\"] = auc_roc\n",
    "\n",
    "    return results\n",
    "\n",
    "# KASUTAMINE! - File_path = jooksutav csv fail!\n",
    "file_path = \"synthetic_data_lung_cancer.csv\"\n",
    "\n",
    "# Run the main script\n",
    "results = main(file_path)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "print(\"\\nAUC-ROC Scores:\")\n",
    "for model_type, auc_roc in results.items():\n",
    "    print(f'{model_type}: {auc_roc}')\n",
    "    counter += 1\n",
    "    if counter == 4:\n",
    "        print()\n",
    "        counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3aac008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Loading_PC1</th>\n",
       "      <th>Absolute_Loading_PC1</th>\n",
       "      <th>Feature.1</th>\n",
       "      <th>Loading_PC2</th>\n",
       "      <th>Absolute_Loading_PC2</th>\n",
       "      <th>Feature.2</th>\n",
       "      <th>Loading_PC3</th>\n",
       "      <th>Absolute_Loading_PC3</th>\n",
       "      <th>Feature.3</th>\n",
       "      <th>...</th>\n",
       "      <th>Absolute_Loading_PC17</th>\n",
       "      <th>Feature.17</th>\n",
       "      <th>Loading_PC18</th>\n",
       "      <th>Absolute_Loading_PC18</th>\n",
       "      <th>Feature.18</th>\n",
       "      <th>Loading_PC19</th>\n",
       "      <th>Absolute_Loading_PC19</th>\n",
       "      <th>Feature.19</th>\n",
       "      <th>Loading_PC20</th>\n",
       "      <th>Absolute_Loading_PC20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>measurement_637</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>0.039471</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>-0.001863</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047339</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>-0.020614</td>\n",
       "      <td>0.020614</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>-0.034442</td>\n",
       "      <td>0.034442</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>0.040120</td>\n",
       "      <td>0.040120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_422</td>\n",
       "      <td>0.030101</td>\n",
       "      <td>0.030101</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>-0.038394</td>\n",
       "      <td>0.038394</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>-0.001390</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007411</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>0.027246</td>\n",
       "      <td>0.027246</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>-0.005919</td>\n",
       "      <td>0.005919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_1076</td>\n",
       "      <td>0.029839</td>\n",
       "      <td>0.029839</td>\n",
       "      <td>measurement_1076</td>\n",
       "      <td>-0.038207</td>\n",
       "      <td>0.038207</td>\n",
       "      <td>measurement_1076</td>\n",
       "      <td>-0.002525</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>measurement_1076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>measurement_1076</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>measurement_1076</td>\n",
       "      <td>-0.005690</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>measurement_1076</td>\n",
       "      <td>-0.002582</td>\n",
       "      <td>0.002582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>0.029795</td>\n",
       "      <td>0.029795</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>-0.036160</td>\n",
       "      <td>0.036160</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>0.004351</td>\n",
       "      <td>0.004351</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033278</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>0.024304</td>\n",
       "      <td>0.024304</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>-0.013304</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>-0.001510</td>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_1027</td>\n",
       "      <td>0.029766</td>\n",
       "      <td>0.029766</td>\n",
       "      <td>measurement_1027</td>\n",
       "      <td>-0.041584</td>\n",
       "      <td>0.041584</td>\n",
       "      <td>measurement_1027</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>measurement_1027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>measurement_1027</td>\n",
       "      <td>-0.005714</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>measurement_1027</td>\n",
       "      <td>0.007213</td>\n",
       "      <td>0.007213</td>\n",
       "      <td>measurement_1027</td>\n",
       "      <td>-0.008015</td>\n",
       "      <td>0.008015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>observation_161</td>\n",
       "      <td>0.019625</td>\n",
       "      <td>0.019625</td>\n",
       "      <td>observation_161</td>\n",
       "      <td>0.023969</td>\n",
       "      <td>0.023969</td>\n",
       "      <td>observation_161</td>\n",
       "      <td>0.045309</td>\n",
       "      <td>0.045309</td>\n",
       "      <td>observation_161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>observation_161</td>\n",
       "      <td>-0.020881</td>\n",
       "      <td>0.020881</td>\n",
       "      <td>observation_161</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>observation_161</td>\n",
       "      <td>0.027901</td>\n",
       "      <td>0.027901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>observation_185</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>observation_185</td>\n",
       "      <td>0.022792</td>\n",
       "      <td>0.022792</td>\n",
       "      <td>observation_185</td>\n",
       "      <td>0.051817</td>\n",
       "      <td>0.051817</td>\n",
       "      <td>observation_185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015765</td>\n",
       "      <td>observation_185</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>observation_185</td>\n",
       "      <td>0.047438</td>\n",
       "      <td>0.047438</td>\n",
       "      <td>observation_185</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.004049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>observation_3</td>\n",
       "      <td>0.019387</td>\n",
       "      <td>0.019387</td>\n",
       "      <td>observation_3</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>observation_3</td>\n",
       "      <td>0.060742</td>\n",
       "      <td>0.060742</td>\n",
       "      <td>observation_3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>observation_3</td>\n",
       "      <td>0.021442</td>\n",
       "      <td>0.021442</td>\n",
       "      <td>observation_3</td>\n",
       "      <td>0.036940</td>\n",
       "      <td>0.036940</td>\n",
       "      <td>observation_3</td>\n",
       "      <td>0.030185</td>\n",
       "      <td>0.030185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>observation_46</td>\n",
       "      <td>0.019248</td>\n",
       "      <td>0.019248</td>\n",
       "      <td>observation_46</td>\n",
       "      <td>0.026371</td>\n",
       "      <td>0.026371</td>\n",
       "      <td>observation_46</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>observation_46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011123</td>\n",
       "      <td>observation_46</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>observation_46</td>\n",
       "      <td>0.021217</td>\n",
       "      <td>0.021217</td>\n",
       "      <td>observation_46</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>measurement_1282</td>\n",
       "      <td>0.018888</td>\n",
       "      <td>0.018888</td>\n",
       "      <td>measurement_1282</td>\n",
       "      <td>0.030002</td>\n",
       "      <td>0.030002</td>\n",
       "      <td>measurement_1282</td>\n",
       "      <td>-0.017046</td>\n",
       "      <td>0.017046</td>\n",
       "      <td>measurement_1282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>measurement_1282</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>measurement_1282</td>\n",
       "      <td>0.049710</td>\n",
       "      <td>0.049710</td>\n",
       "      <td>measurement_1282</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>0.024991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1556 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Loading_PC1  Absolute_Loading_PC1         Feature.1  \\\n",
       "0      measurement_637     0.031130              0.031130   measurement_637   \n",
       "1      measurement_422     0.030101              0.030101   measurement_422   \n",
       "2     measurement_1076     0.029839              0.029839  measurement_1076   \n",
       "3     measurement_1221     0.029795              0.029795  measurement_1221   \n",
       "4     measurement_1027     0.029766              0.029766  measurement_1027   \n",
       "...                ...          ...                   ...               ...   \n",
       "1551   observation_161     0.019625              0.019625   observation_161   \n",
       "1552   observation_185     0.019429              0.019429   observation_185   \n",
       "1553     observation_3     0.019387              0.019387     observation_3   \n",
       "1554    observation_46     0.019248              0.019248    observation_46   \n",
       "1555  measurement_1282     0.018888              0.018888  measurement_1282   \n",
       "\n",
       "      Loading_PC2  Absolute_Loading_PC2         Feature.2  Loading_PC3  \\\n",
       "0       -0.039471              0.039471   measurement_637    -0.001863   \n",
       "1       -0.038394              0.038394   measurement_422    -0.001390   \n",
       "2       -0.038207              0.038207  measurement_1076    -0.002525   \n",
       "3       -0.036160              0.036160  measurement_1221     0.004351   \n",
       "4       -0.041584              0.041584  measurement_1027    -0.000435   \n",
       "...           ...                   ...               ...          ...   \n",
       "1551     0.023969              0.023969   observation_161     0.045309   \n",
       "1552     0.022792              0.022792   observation_185     0.051817   \n",
       "1553     0.024326              0.024326     observation_3     0.060742   \n",
       "1554     0.026371              0.026371    observation_46     0.053802   \n",
       "1555     0.030002              0.030002  measurement_1282    -0.017046   \n",
       "\n",
       "      Absolute_Loading_PC3         Feature.3  ...  Absolute_Loading_PC17  \\\n",
       "0                 0.001863   measurement_637  ...               0.047339   \n",
       "1                 0.001390   measurement_422  ...               0.007411   \n",
       "2                 0.002525  measurement_1076  ...               0.024858   \n",
       "3                 0.004351  measurement_1221  ...               0.033278   \n",
       "4                 0.000435  measurement_1027  ...               0.030098   \n",
       "...                    ...               ...  ...                    ...   \n",
       "1551              0.045309   observation_161  ...               0.009348   \n",
       "1552              0.051817   observation_185  ...               0.015765   \n",
       "1553              0.060742     observation_3  ...               0.011045   \n",
       "1554              0.053802    observation_46  ...               0.011123   \n",
       "1555              0.017046  measurement_1282  ...               0.009857   \n",
       "\n",
       "            Feature.17 Loading_PC18  Absolute_Loading_PC18        Feature.18  \\\n",
       "0      measurement_637    -0.020614               0.020614   measurement_637   \n",
       "1      measurement_422     0.027246               0.027246   measurement_422   \n",
       "2     measurement_1076     0.002208               0.002208  measurement_1076   \n",
       "3     measurement_1221     0.024304               0.024304  measurement_1221   \n",
       "4     measurement_1027    -0.005714               0.005714  measurement_1027   \n",
       "...                ...          ...                    ...               ...   \n",
       "1551   observation_161    -0.020881               0.020881   observation_161   \n",
       "1552   observation_185     0.013730               0.013730   observation_185   \n",
       "1553     observation_3     0.021442               0.021442     observation_3   \n",
       "1554    observation_46    -0.010246               0.010246    observation_46   \n",
       "1555  measurement_1282     0.023762               0.023762  measurement_1282   \n",
       "\n",
       "     Loading_PC19  Absolute_Loading_PC19        Feature.19 Loading_PC20  \\\n",
       "0       -0.034442               0.034442   measurement_637     0.040120   \n",
       "1        0.013040               0.013040   measurement_422    -0.005919   \n",
       "2       -0.005690               0.005690  measurement_1076    -0.002582   \n",
       "3       -0.013304               0.013304  measurement_1221    -0.001510   \n",
       "4        0.007213               0.007213  measurement_1027    -0.008015   \n",
       "...           ...                    ...               ...          ...   \n",
       "1551     0.008554               0.008554   observation_161     0.027901   \n",
       "1552     0.047438               0.047438   observation_185     0.004049   \n",
       "1553     0.036940               0.036940     observation_3     0.030185   \n",
       "1554     0.021217               0.021217    observation_46     0.000489   \n",
       "1555     0.049710               0.049710  measurement_1282     0.024991   \n",
       "\n",
       "      Absolute_Loading_PC20  \n",
       "0                  0.040120  \n",
       "1                  0.005919  \n",
       "2                  0.002582  \n",
       "3                  0.001510  \n",
       "4                  0.008015  \n",
       "...                     ...  \n",
       "1551               0.027901  \n",
       "1552               0.004049  \n",
       "1553               0.030185  \n",
       "1554               0.000489  \n",
       "1555               0.024991  \n",
       "\n",
       "[1556 rows x 60 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings = pd.read_csv(\"combined_loadings.csv\")\n",
    "\n",
    "# Siin peaks teil loadings df avanema kui kõik töötas nii nagu pidi\n",
    "loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f498dde",
   "metadata": {},
   "source": [
    "## Korrelatsioonimaatriks\n",
    "**(Proovime võimalikult palju infot tunnuste kohta hankida kui võimalik juhul kui PCA loadingutest ei piisa)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c4eee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LISAGE SIIA OMA FAIL\n",
    "file = \"synthetic_data_lung_cancer.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d29d14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39770/1291404932.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEFINITION_ID</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>death</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_258</td>\n",
       "      <td>0.308031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_601</td>\n",
       "      <td>0.307923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measurement_817</td>\n",
       "      <td>0.305948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_1325</td>\n",
       "      <td>0.305563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>condition_434</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>condition_1834</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>condition_1885</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>condition_1685</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4863</th>\n",
       "      <td>condition_923</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4864 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DEFINITION_ID     death\n",
       "0                death  1.000000\n",
       "1      measurement_258  0.308031\n",
       "2      measurement_601  0.307923\n",
       "3      measurement_817  0.305948\n",
       "4     measurement_1325  0.305563\n",
       "...                ...       ...\n",
       "4859     condition_434  0.000991\n",
       "4860    condition_1834  0.000696\n",
       "4861    condition_1885  0.000189\n",
       "4862    condition_1685  0.000032\n",
       "4863     condition_923  0.000032\n",
       "\n",
       "[4864 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file                 \n",
    "data = load_data(file)\n",
    "correlation_matrix = data.corr()\n",
    "correlation_with_target = correlation_matrix['death'].abs().sort_values(ascending=False)\n",
    "correlation_with_target.to_csv('correlation_results.csv', header=True)\n",
    "correlations = pd.read_csv(\"correlation_results.csv\")\n",
    "\n",
    "# Siin peaks teil correlations df avanema kui kõik töötas nii nagu pidi\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9914d",
   "metadata": {},
   "source": [
    "## Mutual information\n",
    "**Mutual information measures the dependence between two random variables<br>Helps to Identify which features are more informative for predicting the target variable in a classification problem. Higher mutual information scores imply a stronger relationship between a feature and the target.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "609802c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39770/1291404932.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/1291404932.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature  Mutual_Information\n",
      "3321   measurement_253            0.093112\n",
      "3630   measurement_531            0.087619\n",
      "2233      condition_85            0.084881\n",
      "3180  measurement_1325            0.084747\n",
      "3969   measurement_837            0.084734\n",
      "3400   measurement_324            0.083806\n",
      "3862   measurement_740            0.083265\n",
      "3253   measurement_192            0.082363\n",
      "3620   measurement_522            0.080798\n",
      "4092   measurement_948            0.080770\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Mutual_Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>measurement_253</td>\n",
       "      <td>0.093112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_531</td>\n",
       "      <td>0.087619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition_85</td>\n",
       "      <td>0.084881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measurement_1325</td>\n",
       "      <td>0.084747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_837</td>\n",
       "      <td>0.084734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>condition_2365</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>condition_2367</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>condition_2369</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>condition_237</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>procedure_99</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4863 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Mutual_Information\n",
       "0      measurement_253            0.093112\n",
       "1      measurement_531            0.087619\n",
       "2         condition_85            0.084881\n",
       "3     measurement_1325            0.084747\n",
       "4      measurement_837            0.084734\n",
       "...                ...                 ...\n",
       "4858    condition_2365            0.000000\n",
       "4859    condition_2367            0.000000\n",
       "4860    condition_2369            0.000000\n",
       "4861     condition_237            0.000000\n",
       "4862      procedure_99            0.000000\n",
       "\n",
       "[4863 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LISAGE SIIA OMA FAIL\n",
    "file = \"synthetic_data_lung_cancer.csv\"\n",
    "\n",
    "data = load_data(file)\n",
    "X = data.drop(columns=['death'])\n",
    "y = data['death']\n",
    "\n",
    "mutual_info = mutual_info_classif(X, y, random_state=42)\n",
    "\n",
    "# Create a DataFrame with feature names and their mutual information scores\n",
    "mi_df = pd.DataFrame({'Feature': X.columns, 'Mutual_Information': mutual_info})\n",
    "\n",
    "# Sort features by mutual information scores (descending order)\n",
    "mi_df = mi_df.sort_values(by='Mutual_Information', ascending=False)\n",
    "\n",
    "print(mi_df.head(10))\n",
    "\n",
    "mi_df.to_csv('mutual_information_results.csv', index=False)\n",
    "mutual_information = pd.read_csv(\"mutual_information_results.csv\")\n",
    "mutual_information # Siin peaks teil mutual_information df avanema kui kõik töötas nii nagu pidi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb94b9",
   "metadata": {},
   "source": [
    "# SMOTE kasutamine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94718e13",
   "metadata": {},
   "source": [
    "**SMOTE kasutamises ei ole me kindlad, kas seda on õige kasutada reaalsete andmete peal, aga treening ja valideerimise andmetel läheb auc-roc skoor kõvasti paremaks<br>Sellegipoolest ei ole me kindlad, et kas seda on mõistlik terviseandmete peal kasutada seega see on hetkel pigem lihtsalt siia kerge lisa ja kui leiate, et SMOTE kasutamine oleks okei siis integreeriksime selle oma töövoogu sisse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad6ab704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39770/467747275.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "/tmp/ipykernel_39770/467747275.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio - PC1: 0.2754\n",
      "Explained Variance Ratio - PC2: 0.0501\n",
      "Explained Variance Ratio - PC3: 0.0374\n",
      "Explained Variance Ratio - PC4: 0.0312\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynthetic_data_lung_cancer.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Run the main script\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m results,loading_df \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAUC-ROC Scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_type, auc_roc \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[11], line 66\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     63\u001b[0m important_features, explained_variance_ratio, pca, loading_df \u001b[38;5;241m=\u001b[39m identify_important_features(X, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# SMOTE kasutatakse peale PCA-d\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m smote \u001b[38;5;241m=\u001b[39m \u001b[43mSMOTE\u001b[49m(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     67\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(important_features, y)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Resmapled df\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SMOTE' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to load data\n",
    "def load_data(file):\n",
    "    data = pd.read_csv(file)\n",
    "    surnud = data[data[\"DEFINITION_ID\"] == \"death\"]\n",
    "    subject_ids = surnud[\"SUBJECT_ID\"]\n",
    "    surnud = data[data[\"SUBJECT_ID\"].isin(subject_ids)]\n",
    "    surnud[\"TIME\"] = 1\n",
    "    elus = data[data[\"DEFINITION_ID\"] != \"death\"]\n",
    "    elus[\"TIME\"] = 1\n",
    "    elus_filtered = elus[~elus[\"SUBJECT_ID\"].isin(surnud[\"SUBJECT_ID\"])]\n",
    "    combined_data = pd.concat([surnud, elus_filtered])\n",
    "    combined_data.sort_values(by='SUBJECT_ID', inplace=True)\n",
    "    combined_data.reset_index(drop=True, inplace=True)\n",
    "    pivot_combined_data = combined_data.pivot_table(index='SUBJECT_ID', columns='DEFINITION_ID', values='TIME', aggfunc='sum', fill_value=0)\n",
    "    \n",
    "    return pivot_combined_data\n",
    "\n",
    "# Function to identify important features\n",
    "def identify_important_features(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    pc_columns = [f'PC_{i+1}' for i in range(n_components)]\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    loadings_pc1 = pca.components_[0]\n",
    "    loading_df = pd.DataFrame({'Feature': X.columns, 'Loading_PC1': loadings_pc1})\n",
    "    loading_df['Absolute_Loading_PC1'] = loading_df['Loading_PC1'].abs()\n",
    "    loading_df = loading_df.sort_values(by='Absolute_Loading_PC1', ascending=False)\n",
    "    print(f'Explained Variance Ratio - PC1: {explained_variance_ratio[0]:.4f}')\n",
    "    print(f'Explained Variance Ratio - PC2: {explained_variance_ratio[1]:.4f}')\n",
    "    print(f'Explained Variance Ratio - PC3: {explained_variance_ratio[2]:.4f}')\n",
    "    print(f'Explained Variance Ratio - PC4: {explained_variance_ratio[3]:.4f}')\n",
    "    return pd.DataFrame(X_pca, columns=pc_columns), explained_variance_ratio, pca, loading_df\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(X, y, model_type):\n",
    "    svm_params = {'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'C': 100}\n",
    "    knn_params = {'weights': 'distance', 'p': 2, 'n_neighbors': 16, 'algorithm': 'auto'}\n",
    "    \n",
    "    if model_type == 'RandomForest':\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    elif model_type == 'SVM':\n",
    "        model = SVC(probability=True, random_state=42,**svm_params)\n",
    "    elif model_type == 'KNeighbors':\n",
    "        model = KNeighborsClassifier(**knn_params)\n",
    "    else:\n",
    "        raise ValueError(f'Invalid model type: {model_type}')\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X, y):\n",
    "    y_probabilities = model.predict_proba(X)[:, 1]\n",
    "    auc_roc = roc_auc_score(y, y_probabilities)\n",
    "    return auc_roc\n",
    "\n",
    "# Function to perform the entire workflow\n",
    "def main(file):\n",
    "    data = load_data(file)\n",
    "    X = data.drop(columns=['death'])\n",
    "    y = data['death']\n",
    "    \n",
    "    important_features, explained_variance_ratio, pca, loading_df = identify_important_features(X, n_components=25)\n",
    "     \n",
    "    # SMOTE kasutatakse peale PCA-d\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(important_features, y)\n",
    "    \n",
    "    # Resmapled df\n",
    "    resampled_data = pd.DataFrame(X_resampled, columns=important_features.columns)\n",
    "    resampled_data['death'] = y_resampled\n",
    "    \n",
    "    model_types = ['RandomForest','SVM', 'KNeighbors']\n",
    "    results = {}\n",
    "    X_train, X_test, y_train, y_test = train_test_split(resampled_data.drop(columns=['death']), resampled_data['death'], test_size=0.2, random_state=42)\n",
    "\n",
    "    for model_type in model_types:\n",
    "        model = train_model(X_train, y_train, model_type=model_type)\n",
    "        auc_roc = evaluate_model(model, X_test, y_test)\n",
    "        results[model_type] = auc_roc\n",
    "        print(f'{model_type} AUC-ROC: {auc_roc}')\n",
    "\n",
    "    return results, loading_df\n",
    "\n",
    "# LISAGE SIIA OMA FAIL\n",
    "file_path = \"synthetic_data_lung_cancer.csv\"\n",
    "\n",
    "# Run the main script\n",
    "results,loading_df = main(file_path)\n",
    "print(\"\\nAUC-ROC Scores:\")\n",
    "for model_type, auc_roc in results.items():\n",
    "    print(f'{model_type}: {auc_roc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacdda5",
   "metadata": {},
   "source": [
    "# Sooviksime siis tagasi saada need kolm csv faili tunnustest\n",
    "**'mutual_information_results.csv'<br>\"correlation_results.csv\"<br>\"combined_loadings.csv\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f5bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
