{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d9af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec995a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install openpyxl Juhul jui juba olemas ei ole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158c082",
   "metadata": {},
   "source": [
    "## Andmete töötlemine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9896ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    \n",
    "    # Data\n",
    "    data = pd.read_csv(file)\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    surnud= data[data[\"DEFINITION_ID\"] == \"death\"]\n",
    "    subject_ids = surnud[\"SUBJECT_ID\"]\n",
    "    \n",
    "    # FIltreerib surnute id põhjal\n",
    "    surnud = data[data[\"SUBJECT_ID\"].isin(subject_ids)]\n",
    "    surnud[\"TIME\"] = 1 # Muudame aja väärtuse 1-ks, ehk esialgsetes andmetes \"DEFINITION_ID\" = TIME, nüüd selle asemel \n",
    "    # lihtsalt 1.\n",
    "    elus = data[data[\"DEFINITION_ID\"] != \"death\"]\n",
    "    elus[\"TIME\"] = 1\n",
    "\n",
    "    # Sama toimub ka siin, aga elus patsientidega\n",
    "    elus_filtered = elus[~elus[\"SUBJECT_ID\"].isin(surnud[\"SUBJECT_ID\"])]\n",
    "\n",
    "    # Filtreeritud andmete kombineerimine üheks tabeliks\n",
    "    combined_data = pd.concat([surnud, elus_filtered])\n",
    "    combined_data.sort_values(by='SUBJECT_ID', inplace=True)\n",
    "    combined_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #Viimane tabel-  kus read on patsiendid, veerud protseduurid vastavalt\n",
    "    # 1- protseduur tehti, 0 - patsient pole protseduuri saanud. samuti ka veerg \"death\": 1-surnud, 0 -\"elus\"\n",
    "    \n",
    "    pivot_combined_data = combined_data.pivot_table(index='SUBJECT_ID', columns='DEFINITION_ID', values='TIME', aggfunc='sum', fill_value=0)\n",
    "    return pivot_combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0f6d9",
   "metadata": {},
   "source": [
    "## Tunnuste töötlemine (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a86fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_important_features(X, save_loadings=False):\n",
    "    n_components=20\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # DataFrame with the principal components\n",
    "    pc_columns = [f'PC_{i+1}' for i in range(n_components)]\n",
    "    \n",
    "    # Variance ratios\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_ \n",
    "    \n",
    "    all_pca_loadings = [loadings for loadings in pca.components_]\n",
    "    \n",
    "    if save_loadings:\n",
    "        loadings_dfs = []\n",
    "        for index, loadings in enumerate(all_pca_loadings):\n",
    "            loadings_df = pd.DataFrame({'Feature': X.columns, f'Loading_PC{index+1}': loadings})\n",
    "            loadings_df[f'Absolute_Loading_PC{index+1}'] = loadings_df[f'Loading_PC{index+1}'].abs()\n",
    "            loadings_df = loadings_df.sort_values(by=f'Absolute_Loading_PC{index+1}', ascending=False)\n",
    "            loadings_dfs.append(loadings_df)\n",
    "        \n",
    "        combined_loadings_df = pd.concat(loadings_dfs, axis=1)\n",
    "        combined_loadings_df.to_csv('combined_loadings.csv', index=False, encoding=\"utf-8\")\n",
    "    print(f'Explained Variance Ratio - PC1: {explained_variance_ratio[0]:.4f}')\n",
    "    print(f'Explained Variance Ratio - PC2: {explained_variance_ratio[1]:.4f}')\n",
    "    print(f'Explained Variance Ratio - PC3: {explained_variance_ratio[2]:.4f}')\n",
    "    print(f'Explained Variance Ratio - PC4: {explained_variance_ratio[3]:.4f}')\n",
    "    \n",
    "    loadings_pc = pca.components_[0]\n",
    "    \n",
    "    # saaks kätte kõige olulisemad feature nimed\n",
    "    loading_df = pd.DataFrame({'Feature': X.columns, 'Loading_PC1': loadings_pc})\n",
    "    \n",
    "    # Sorteeritud\n",
    "    loading_df['Absolute_Loading_PC1'] = loading_df['Loading_PC1'].abs()\n",
    "    loading_df = loading_df.sort_values(by='Absolute_Loading_PC1', ascending=False)\n",
    "    \n",
    "    return pd.DataFrame(X_pca, columns=pc_columns), explained_variance_ratio, pca, loading_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb364e9d",
   "metadata": {},
   "source": [
    "## Erinevate mudelite treenimine, valimaks parima mudeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49f6518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model_type):\n",
    "    svm_params = {'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'C': 100}\n",
    "    knn_params = {'weights': 'distance', 'p': 2, 'n_neighbors': 16, 'algorithm': 'auto'}\n",
    "    rf_params = {'bootstrap': False, 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "    gradient_params = {'learning_rate': 0.2, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
    "    if model_type == 'RandomForest':\n",
    "        model = RandomForestClassifier(random_state=42,**rf_params)\n",
    "    elif model_type == 'SVM':\n",
    "        model = SVC(probability=True, random_state=42,**svm_params)\n",
    "    elif model_type == 'KNeighbors':\n",
    "        model = KNeighborsClassifier(**knn_params)\n",
    "    elif model_type == \"Gradient\":\n",
    "        model = GradientBoostingClassifier(random_state=42,**gradient_params)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f'Invalid model type: {model_type}')\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde9994",
   "metadata": {},
   "source": [
    "## Mudeli hindamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d659cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    # Mudeli hindamine \n",
    "    y_probabilities = model.predict_proba(X)[:, 1]    \n",
    "    auc_roc = roc_auc_score(y, y_probabilities)\n",
    "    \n",
    "    return auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c35ac7",
   "metadata": {},
   "source": [
    "## Töövoo jooksutamine\n",
    "**PS! Vaata #STEP 2 juures kommentaar \"save_loadings\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dcc91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\AppData\\Local\\Temp\\ipykernel_25308\\2053188126.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1 # Muudame aja väärtuse 1-ks, ehk esialgsetes andmetes \"DEFINITION_ID\" = TIME, nüüd selle asemel\n",
      "C:\\Users\\rober\\AppData\\Local\\Temp\\ipykernel_25308\\2053188126.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio - PC1: 0.2754\n",
      "Explained Variance Ratio - PC2: 0.0501\n",
      "Explained Variance Ratio - PC3: 0.0374\n",
      "Explained Variance Ratio - PC4: 0.0312\n",
      "RandomForest AUC-ROC: 0.8241137954391511\n",
      "SVM AUC-ROC: 0.8778505305938135\n",
      "KNeighbors AUC-ROC: 0.8516595168209529\n",
      "Gradient AUC-ROC: 0.8814630842176564\n",
      "\n",
      "AUC-ROC Scores:\n",
      "RandomForest: 0.8241137954391511\n",
      "SVM: 0.8778505305938135\n",
      "KNeighbors: 0.8516595168209529\n",
      "Gradient: 0.8814630842176564\n"
     ]
    }
   ],
   "source": [
    "def main(file):\n",
    "    \n",
    "    # Step 1: Load data\n",
    "    data = load_data(file)\n",
    "    X = data.drop(columns=['death'])\n",
    "    y = data['death']\n",
    "    \n",
    "    # Step 2: important features\n",
    "        # PANNA \"save_loadings=True\" et tekiks uus csv fail kust saame hiljem tunnuste osakaalu PCA-de moodustamisel vaadata\n",
    "    important_features, explained_variance_ratio, pca, loading_df = identify_important_features(X,save_loadings=True)\n",
    "    \n",
    "    model_types = ['RandomForest','SVM', 'KNeighbors','Gradient'] #Different models to try\n",
    "    results = {} #Results\n",
    "    \n",
    "    # Step 3: Mudelite treenimine (important_features ehk saadud PCA eelnevas sammus)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(important_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for model_type in model_types:\n",
    "        model = train_model(X_train, y_train, model_type=model_type)\n",
    "        auc_roc = evaluate_model(model, X_test, y_test)\n",
    "        results[model_type] = auc_roc\n",
    "        print(f'{model_type} AUC-ROC: {auc_roc}')\n",
    "\n",
    "    return results\n",
    "\n",
    "# KASUTAMINE! - File_path = jooksutav csv fail!\n",
    "file_path = #SIIA TEIE FAIL    #\"synthetic_data_lung_cancer.csv\"\n",
    "\n",
    "# Run the main script\n",
    "results = main(file_path)\n",
    "print(\"\\nAUC-ROC Scores:\")\n",
    "for model_type, auc_roc in results.items():\n",
    "    print(f'{model_type}: {auc_roc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3aac008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Loading_PC1</th>\n",
       "      <th>Absolute_Loading_PC1</th>\n",
       "      <th>Feature.1</th>\n",
       "      <th>Loading_PC2</th>\n",
       "      <th>Absolute_Loading_PC2</th>\n",
       "      <th>Feature.2</th>\n",
       "      <th>Loading_PC3</th>\n",
       "      <th>Absolute_Loading_PC3</th>\n",
       "      <th>Feature.3</th>\n",
       "      <th>...</th>\n",
       "      <th>Absolute_Loading_PC17</th>\n",
       "      <th>Feature.17</th>\n",
       "      <th>Loading_PC18</th>\n",
       "      <th>Absolute_Loading_PC18</th>\n",
       "      <th>Feature.18</th>\n",
       "      <th>Loading_PC19</th>\n",
       "      <th>Absolute_Loading_PC19</th>\n",
       "      <th>Feature.19</th>\n",
       "      <th>Loading_PC20</th>\n",
       "      <th>Absolute_Loading_PC20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>measurement_637</td>\n",
       "      <td>0.029168</td>\n",
       "      <td>0.029168</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>-0.017191</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>-0.035745</td>\n",
       "      <td>0.035745</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>measurement_637</td>\n",
       "      <td>-0.016075</td>\n",
       "      <td>0.016075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>observation_204</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>observation_204</td>\n",
       "      <td>0.052606</td>\n",
       "      <td>0.052606</td>\n",
       "      <td>observation_204</td>\n",
       "      <td>-0.002151</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>observation_204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040111</td>\n",
       "      <td>observation_204</td>\n",
       "      <td>0.038865</td>\n",
       "      <td>0.038865</td>\n",
       "      <td>observation_204</td>\n",
       "      <td>-0.034777</td>\n",
       "      <td>0.034777</td>\n",
       "      <td>observation_204</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>0.007131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>observation_224</td>\n",
       "      <td>0.028194</td>\n",
       "      <td>0.028194</td>\n",
       "      <td>observation_224</td>\n",
       "      <td>0.041922</td>\n",
       "      <td>0.041922</td>\n",
       "      <td>observation_224</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>observation_224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030885</td>\n",
       "      <td>observation_224</td>\n",
       "      <td>-0.063765</td>\n",
       "      <td>0.063765</td>\n",
       "      <td>observation_224</td>\n",
       "      <td>-0.026130</td>\n",
       "      <td>0.026130</td>\n",
       "      <td>observation_224</td>\n",
       "      <td>0.011379</td>\n",
       "      <td>0.011379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measurement_422</td>\n",
       "      <td>0.028162</td>\n",
       "      <td>0.028162</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>-0.016644</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>-0.035846</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>0.011477</td>\n",
       "      <td>0.011477</td>\n",
       "      <td>measurement_422</td>\n",
       "      <td>-0.023523</td>\n",
       "      <td>0.023523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>0.028010</td>\n",
       "      <td>0.028010</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>-0.034729</td>\n",
       "      <td>0.034729</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>0.017111</td>\n",
       "      <td>0.017111</td>\n",
       "      <td>measurement_1221</td>\n",
       "      <td>-0.017852</td>\n",
       "      <td>0.017852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>condition_2161</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>condition_2161</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>condition_2161</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>condition_2161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>condition_2161</td>\n",
       "      <td>0.009922</td>\n",
       "      <td>0.009922</td>\n",
       "      <td>condition_2161</td>\n",
       "      <td>-0.016060</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>condition_2161</td>\n",
       "      <td>-0.019381</td>\n",
       "      <td>0.019381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>condition_2394</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>condition_2394</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>condition_2394</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>condition_2394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>condition_2394</td>\n",
       "      <td>0.009965</td>\n",
       "      <td>0.009965</td>\n",
       "      <td>condition_2394</td>\n",
       "      <td>0.006358</td>\n",
       "      <td>0.006358</td>\n",
       "      <td>condition_2394</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.001303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>condition_1750</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>condition_1750</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>condition_1750</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>condition_1750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>condition_1750</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>condition_1750</td>\n",
       "      <td>-0.013261</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>condition_1750</td>\n",
       "      <td>-0.021822</td>\n",
       "      <td>0.021822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>condition_53</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>condition_53</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>condition_53</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>condition_53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015942</td>\n",
       "      <td>condition_53</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>condition_53</td>\n",
       "      <td>-0.020206</td>\n",
       "      <td>0.020206</td>\n",
       "      <td>condition_53</td>\n",
       "      <td>-0.014784</td>\n",
       "      <td>0.014784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>condition_241</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>condition_241</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>condition_241</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>condition_241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>condition_241</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>condition_241</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>condition_241</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>0.007907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4863 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Loading_PC1  Absolute_Loading_PC1         Feature.1  \\\n",
       "0      measurement_637     0.029168              0.029168   measurement_637   \n",
       "1      observation_204     0.028583              0.028583   observation_204   \n",
       "2      observation_224     0.028194              0.028194   observation_224   \n",
       "3      measurement_422     0.028162              0.028162   measurement_422   \n",
       "4     measurement_1221     0.028010              0.028010  measurement_1221   \n",
       "...                ...          ...                   ...               ...   \n",
       "4858    condition_2161     0.001545              0.001545    condition_2161   \n",
       "4859    condition_2394     0.001500              0.001500    condition_2394   \n",
       "4860    condition_1750     0.001423              0.001423    condition_1750   \n",
       "4861      condition_53     0.001403              0.001403      condition_53   \n",
       "4862     condition_241     0.001230              0.001230     condition_241   \n",
       "\n",
       "      Loading_PC2  Absolute_Loading_PC2         Feature.2  Loading_PC3  \\\n",
       "0       -0.017191              0.017191   measurement_637    -0.035745   \n",
       "1        0.052606              0.052606   observation_204    -0.002151   \n",
       "2        0.041922              0.041922   observation_224     0.004933   \n",
       "3       -0.016644              0.016644   measurement_422    -0.035846   \n",
       "4       -0.012115              0.012115  measurement_1221    -0.034729   \n",
       "...           ...                   ...               ...          ...   \n",
       "4858     0.004886              0.004886    condition_2161     0.002884   \n",
       "4859     0.002474              0.002474    condition_2394     0.006338   \n",
       "4860     0.003596              0.003596    condition_1750     0.000244   \n",
       "4861     0.006980              0.006980      condition_53    -0.001001   \n",
       "4862     0.003632              0.003632     condition_241     0.000002   \n",
       "\n",
       "      Absolute_Loading_PC3         Feature.3  ...  Absolute_Loading_PC17  \\\n",
       "0                 0.035745   measurement_637  ...               0.005995   \n",
       "1                 0.002151   observation_204  ...               0.040111   \n",
       "2                 0.004933   observation_224  ...               0.030885   \n",
       "3                 0.035846   measurement_422  ...               0.000532   \n",
       "4                 0.034729  measurement_1221  ...               0.002710   \n",
       "...                    ...               ...  ...                    ...   \n",
       "4858              0.002884    condition_2161  ...               0.009180   \n",
       "4859              0.006338    condition_2394  ...               0.003899   \n",
       "4860              0.000244    condition_1750  ...               0.003946   \n",
       "4861              0.001001      condition_53  ...               0.015942   \n",
       "4862              0.000002     condition_241  ...               0.005145   \n",
       "\n",
       "            Feature.17 Loading_PC18  Absolute_Loading_PC18        Feature.18  \\\n",
       "0      measurement_637     0.002097               0.002097   measurement_637   \n",
       "1      observation_204     0.038865               0.038865   observation_204   \n",
       "2      observation_224    -0.063765               0.063765   observation_224   \n",
       "3      measurement_422     0.008315               0.008315   measurement_422   \n",
       "4     measurement_1221     0.009182               0.009182  measurement_1221   \n",
       "...                ...          ...                    ...               ...   \n",
       "4858    condition_2161     0.009922               0.009922    condition_2161   \n",
       "4859    condition_2394     0.009965               0.009965    condition_2394   \n",
       "4860    condition_1750     0.007396               0.007396    condition_1750   \n",
       "4861      condition_53     0.008729               0.008729      condition_53   \n",
       "4862     condition_241     0.009141               0.009141     condition_241   \n",
       "\n",
       "     Loading_PC19  Absolute_Loading_PC19        Feature.19 Loading_PC20  \\\n",
       "0        0.001676               0.001676   measurement_637    -0.016075   \n",
       "1       -0.034777               0.034777   observation_204     0.007131   \n",
       "2       -0.026130               0.026130   observation_224     0.011379   \n",
       "3        0.011477               0.011477   measurement_422    -0.023523   \n",
       "4        0.017111               0.017111  measurement_1221    -0.017852   \n",
       "...           ...                    ...               ...          ...   \n",
       "4858    -0.016060               0.016060    condition_2161    -0.019381   \n",
       "4859     0.006358               0.006358    condition_2394     0.001303   \n",
       "4860    -0.013261               0.013261    condition_1750    -0.021822   \n",
       "4861    -0.020206               0.020206      condition_53    -0.014784   \n",
       "4862    -0.000068               0.000068     condition_241    -0.007907   \n",
       "\n",
       "      Absolute_Loading_PC20  \n",
       "0                  0.016075  \n",
       "1                  0.007131  \n",
       "2                  0.011379  \n",
       "3                  0.023523  \n",
       "4                  0.017852  \n",
       "...                     ...  \n",
       "4858               0.019381  \n",
       "4859               0.001303  \n",
       "4860               0.021822  \n",
       "4861               0.014784  \n",
       "4862               0.007907  \n",
       "\n",
       "[4863 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings = pd.read_csv(\"combined_loadings.csv\")\n",
    "loadings # Siin peaks teil loadings df avanema kui kõik töötas nii nagu pidi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f498dde",
   "metadata": {},
   "source": [
    "## Korrelatsioonimaatriks\n",
    "**(Proovime võimalikult palju infot tunnuste kohta hankida kui võimalik juhul kui PCA loadingutest ei piisa)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4eee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file ='' # LISAGE SIIA OMA FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d29d14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\AppData\\Local\\Temp\\ipykernel_25308\\2053188126.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1 # Muudame aja väärtuse 1-ks, ehk esialgsetes andmetes \"DEFINITION_ID\" = TIME, nüüd selle asemel\n",
      "C:\\Users\\rober\\AppData\\Local\\Temp\\ipykernel_25308\\2053188126.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEFINITION_ID</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>death</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_258</td>\n",
       "      <td>0.308031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_601</td>\n",
       "      <td>0.307923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measurement_817</td>\n",
       "      <td>0.305948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_1325</td>\n",
       "      <td>0.305563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>condition_434</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>condition_1834</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>condition_1885</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>condition_1685</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4863</th>\n",
       "      <td>condition_923</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4864 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DEFINITION_ID     death\n",
       "0                death  1.000000\n",
       "1      measurement_258  0.308031\n",
       "2      measurement_601  0.307923\n",
       "3      measurement_817  0.305948\n",
       "4     measurement_1325  0.305563\n",
       "...                ...       ...\n",
       "4859     condition_434  0.000991\n",
       "4860    condition_1834  0.000696\n",
       "4861    condition_1885  0.000189\n",
       "4862    condition_1685  0.000032\n",
       "4863     condition_923  0.000032\n",
       "\n",
       "[4864 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file                 \n",
    "data = load_data(file)\n",
    "correlation_matrix = data.corr()\n",
    "correlation_with_target = correlation_matrix['death'].abs().sort_values(ascending=False)\n",
    "correlation_with_target.to_csv('correlation_results.csv', header=True)\n",
    "correlations = pd.read_csv(\"correlation_results.csv\")\n",
    "correlations # Siin peaks teil correlations df avanema kui kõik töötas nii nagu pidi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9914d",
   "metadata": {},
   "source": [
    "## Mutual information\n",
    "**Mutual information measures the dependence between two random variables<br>Helps to Identify which features are more informative for predicting the target variable in a classification problem. Higher mutual information scores imply a stronger relationship between a feature and the target.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "609802c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\AppData\\Local\\Temp\\ipykernel_25308\\2053188126.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1 # Muudame aja väärtuse 1-ks, ehk esialgsetes andmetes \"DEFINITION_ID\" = TIME, nüüd selle asemel\n",
      "C:\\Users\\rober\\AppData\\Local\\Temp\\ipykernel_25308\\2053188126.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature  Mutual_Information\n",
      "3321   measurement_253            0.093112\n",
      "3630   measurement_531            0.087619\n",
      "2233      condition_85            0.084881\n",
      "3180  measurement_1325            0.084747\n",
      "3969   measurement_837            0.084734\n",
      "3400   measurement_324            0.083806\n",
      "3862   measurement_740            0.083265\n",
      "3253   measurement_192            0.082363\n",
      "3620   measurement_522            0.080798\n",
      "4092   measurement_948            0.080770\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Mutual_Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>measurement_253</td>\n",
       "      <td>0.093112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_531</td>\n",
       "      <td>0.087619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition_85</td>\n",
       "      <td>0.084881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measurement_1325</td>\n",
       "      <td>0.084747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_837</td>\n",
       "      <td>0.084734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>condition_2365</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>condition_2367</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>condition_2369</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>condition_237</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>procedure_99</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4863 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Mutual_Information\n",
       "0      measurement_253            0.093112\n",
       "1      measurement_531            0.087619\n",
       "2         condition_85            0.084881\n",
       "3     measurement_1325            0.084747\n",
       "4      measurement_837            0.084734\n",
       "...                ...                 ...\n",
       "4858    condition_2365            0.000000\n",
       "4859    condition_2367            0.000000\n",
       "4860    condition_2369            0.000000\n",
       "4861     condition_237            0.000000\n",
       "4862      procedure_99            0.000000\n",
       "\n",
       "[4863 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file# = \"synthetic_data_lung_cancer.csv\"\n",
    "data = load_data(file)\n",
    "X = data.drop(columns=['death'])\n",
    "y = data['death']\n",
    "\n",
    "\n",
    "mutual_info = mutual_info_classif(X, y,random_state=42)\n",
    "\n",
    "# Create a DataFrame with feature names and their mutual information scores\n",
    "mi_df = pd.DataFrame({'Feature': X.columns, 'Mutual_Information': mutual_info})\n",
    "\n",
    "# Sort features by mutual information scores (descending order)\n",
    "mi_df = mi_df.sort_values(by='Mutual_Information', ascending=False)\n",
    "\n",
    "print(mi_df.head(10))\n",
    "\n",
    "mi_df.to_csv('mutual_information_results.csv', index=False)\n",
    "mutual_information = pd.read_csv(\"mutual_information_results.csv\")\n",
    "mutual_information # Siin peaks teil mutual_information df avanema kui kõik töötas nii nagu pidi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0dd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91eb94b9",
   "metadata": {},
   "source": [
    "# SMOTE kasutamine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94718e13",
   "metadata": {},
   "source": [
    "**SMOTE kasutamises ei ole me kindlad, kas seda on õige kasutada reaalsete andmete peal, aga treening ja valideerimise andmetel läheb auc-roc skoor kõvasti paremaks<br>Sellegipoolest ei ole me kindlad, et kas seda on mõistlik terviseandmete peal kasutada seega see on hetkel pigem lihtsalt siia kerge lisa ja kui leiate, et SMOTE kasutamine oleks okei siis integreeriksime selle oma töövoogu sisse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad6ab704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\AppData\\Local\\Temp\\ipykernel_25308\\663592784.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  surnud[\"TIME\"] = 1\n",
      "C:\\Users\\rober\\AppData\\Local\\Temp\\ipykernel_25308\\663592784.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  elus[\"TIME\"] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio - PC1: 0.2754\n",
      "Explained Variance Ratio - PC2: 0.0501\n",
      "Explained Variance Ratio - PC3: 0.0374\n",
      "Explained Variance Ratio - PC4: 0.0312\n",
      "RandomForest AUC-ROC: 0.9438058748403576\n",
      "SVM AUC-ROC: 0.9106002554278416\n",
      "KNeighbors AUC-ROC: 0.9059561128526646\n",
      "\n",
      "AUC-ROC Scores:\n",
      "RandomForest: 0.9438058748403576\n",
      "SVM: 0.9106002554278416\n",
      "KNeighbors: 0.9059561128526646\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to load data\n",
    "def load_data(file):\n",
    "    data = pd.read_csv(file)\n",
    "    surnud = data[data[\"DEFINITION_ID\"] == \"death\"]\n",
    "    subject_ids = surnud[\"SUBJECT_ID\"]\n",
    "    surnud = data[data[\"SUBJECT_ID\"].isin(subject_ids)]\n",
    "    surnud[\"TIME\"] = 1\n",
    "    elus = data[data[\"DEFINITION_ID\"] != \"death\"]\n",
    "    elus[\"TIME\"] = 1\n",
    "    elus_filtered = elus[~elus[\"SUBJECT_ID\"].isin(surnud[\"SUBJECT_ID\"])]\n",
    "    combined_data = pd.concat([surnud, elus_filtered])\n",
    "    combined_data.sort_values(by='SUBJECT_ID', inplace=True)\n",
    "    combined_data.reset_index(drop=True, inplace=True)\n",
    "    pivot_combined_data = combined_data.pivot_table(index='SUBJECT_ID', columns='DEFINITION_ID', values='TIME', aggfunc='sum', fill_value=0)\n",
    "    \n",
    "    return pivot_combined_data\n",
    "\n",
    "# Function to identify important features\n",
    "def identify_important_features(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    pc_columns = [f'PC_{i+1}' for i in range(n_components)]\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    loadings_pc1 = pca.components_[0]\n",
    "    loading_df = pd.DataFrame({'Feature': X.columns, 'Loading_PC1': loadings_pc1})\n",
    "    loading_df['Absolute_Loading_PC1'] = loading_df['Loading_PC1'].abs()\n",
    "    loading_df = loading_df.sort_values(by='Absolute_Loading_PC1', ascending=False)\n",
    "    print(f'Explained Variance Ratio - PC1: {explained_variance_ratio[0]:.4f}')\n",
    "    print(f'Explained Variance Ratio - PC2: {explained_variance_ratio[1]:.4f}')\n",
    "    print(f'Explained Variance Ratio - PC3: {explained_variance_ratio[2]:.4f}')\n",
    "    print(f'Explained Variance Ratio - PC4: {explained_variance_ratio[3]:.4f}')\n",
    "    return pd.DataFrame(X_pca, columns=pc_columns), explained_variance_ratio, pca, loading_df\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(X, y, model_type):\n",
    "    svm_params = {'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'C': 100}\n",
    "    knn_params = {'weights': 'distance', 'p': 2, 'n_neighbors': 16, 'algorithm': 'auto'}\n",
    "    \n",
    "    if model_type == 'RandomForest':\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    elif model_type == 'SVM':\n",
    "        model = SVC(probability=True, random_state=42,**svm_params)\n",
    "    elif model_type == 'KNeighbors':\n",
    "        model = KNeighborsClassifier(**knn_params)\n",
    "    else:\n",
    "        raise ValueError(f'Invalid model type: {model_type}')\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X, y):\n",
    "    y_probabilities = model.predict_proba(X)[:, 1]\n",
    "    auc_roc = roc_auc_score(y, y_probabilities)\n",
    "    return auc_roc\n",
    "\n",
    "# Function to perform the entire workflow\n",
    "def main(file):\n",
    "    data = load_data(file)\n",
    "    X = data.drop(columns=['death'])\n",
    "    y = data['death']\n",
    "    \n",
    "    important_features, explained_variance_ratio, pca, loading_df = identify_important_features(X, n_components=25)\n",
    "     \n",
    "    # SMOTE kasutatakse peale PCA-d\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(important_features, y)\n",
    "    \n",
    "    # Resmapled df\n",
    "    resampled_data = pd.DataFrame(X_resampled, columns=important_features.columns)\n",
    "    resampled_data['death'] = y_resampled\n",
    "    \n",
    "    model_types = ['RandomForest','SVM', 'KNeighbors']\n",
    "    results = {}\n",
    "    X_train, X_test, y_train, y_test = train_test_split(resampled_data.drop(columns=['death']), resampled_data['death'], test_size=0.2, random_state=42)\n",
    "\n",
    "    for model_type in model_types:\n",
    "        model = train_model(X_train, y_train, model_type=model_type)\n",
    "        auc_roc = evaluate_model(model, X_test, y_test)\n",
    "        results[model_type] = auc_roc\n",
    "        print(f'{model_type} AUC-ROC: {auc_roc}')\n",
    "\n",
    "    return results, loading_df\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"synthetic_data_lung_cancer.csv\" #\"synthetic_data_lung_cancer.csv\"\n",
    "\n",
    "# Run the main script\n",
    "results,loading_df = main(file_path)\n",
    "print(\"\\nAUC-ROC Scores:\")\n",
    "for model_type, auc_roc in results.items():\n",
    "    print(f'{model_type}: {auc_roc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacdda5",
   "metadata": {},
   "source": [
    "# Sooviksime siis tagasi saada need kolm csv faili tunnustest\n",
    "**'mutual_information_results.csv'<br>\"correlation_results.csv\"<br>\"combined_loadings.csv\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f5bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
